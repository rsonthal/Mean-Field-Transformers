{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsNadJLO_CPq",
        "outputId": "4fcc18cb-523c-4b10-ee42-b7dfe77e4353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.1 cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "TORCH = torch.__version__.split('+')[0]\n",
        "CUDA = 'cu' + torch.version.cuda.replace('.','')\n",
        "print(TORCH, CUDA)\n",
        "\n",
        "import pickle\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6npCCK-_JtD"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyg_lib -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "!pip install torch-scatter     -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QG5QUEIe_M2L"
      },
      "outputs": [],
      "source": [
        "import torch_geometric\n",
        "import torch_geometric.nn as geom_nn\n",
        "import torch_geometric.data as geom_data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data import InMemoryDataset\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "from scipy.linalg import fractional_matrix_power\n",
        "from scipy.spatial.distance import pdist\n",
        "from scipy.spatial.distance import squareform\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as matplotlib\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import math\n",
        "from numba import cuda\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.utils import (\n",
        "    to_networkx,\n",
        "    from_networkx,\n",
        "    to_dense_adj,\n",
        "    remove_self_loops,\n",
        "    to_undirected,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v77ZZalQ_O5D",
        "outputId": "73af740c-797e-44a7-e489-574326bc98f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4atzWaGU_Rj1"
      },
      "source": [
        "# Set up Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7e_hwuG_REL"
      },
      "outputs": [],
      "source": [
        "def data_to_kNN(X,k):\n",
        "  edge_index = torch_geometric.nn.knn_graph(X, k)\n",
        "  edge_index = to_undirected(edge_index, num_nodes=X.shape[0])\n",
        "  return edge_index\n",
        "\n",
        "def data_to_GNN_data(X,Y,k):\n",
        "  dataset = []\n",
        "  N = X.shape[0]\n",
        "  for i in range(N):\n",
        "    data = Data(x = X[i,:,:], y = Y[i,:,:], edge_index = data_to_kNN(X[i,:,:],k))\n",
        "    data.num_nodes = 20\n",
        "    data.num_edges = data.edge_index.shape[1]\n",
        "    dataset.append(data)\n",
        "  return dataset\n",
        "\n",
        "def data_to_GNN_data_fm(X,Y,k):\n",
        "  dataset = []\n",
        "  N = len(X)\n",
        "  for i in tqdm(range(N)):\n",
        "    data = Data(x = X[i], y = Y[i], edge_index = data_to_kNN(X[i],k))\n",
        "    data.num_nodes = X[i].shape[0]\n",
        "    data.num_edges = data.edge_index.shape[1]\n",
        "    dataset.append(data)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbBR8QuND5zv"
      },
      "source": [
        "# Preprocessing Fish Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2Td10RkD2Qd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Opening JSON file\n",
        "f = open('drive/MyDrive/MeasureMaps/schooling_frames.json')\n",
        "\n",
        "# returns JSON object as\n",
        "# a dictionary\n",
        "data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4_TzgovwqXY"
      },
      "outputs": [],
      "source": [
        "fish_ids_to_idx = dict()\n",
        "\n",
        "idx = 0\n",
        "for i in range(1,len(data)+1):\n",
        "  curr_time = data[str(i)]\n",
        "  fish_idx = data[str(i)][\"onfish\"]\n",
        "  for j in range(len(fish_idx)):\n",
        "    if fish_idx[j] not in fish_ids_to_idx:\n",
        "      fish = dict()\n",
        "      fish[\"id\"] = idx\n",
        "      fish[\"times\"] = [i]\n",
        "      fish[\"x\"] = torch.tensor([curr_time[\"px\"][j], curr_time[\"py\"][j], curr_time[\"vx\"][j], curr_time[\"vy\"][j]]).unsqueeze(0)\n",
        "      fish_ids_to_idx[fish_idx[j]] = fish\n",
        "      idx += 1\n",
        "    else:\n",
        "      fish = fish_ids_to_idx[fish_idx[j]]\n",
        "      fish[\"times\"].append(i)\n",
        "      try:\n",
        "        x = torch.tensor([curr_time[\"px\"][j], curr_time[\"py\"][j], curr_time[\"vx\"][j], curr_time[\"vy\"][j]]).unsqueeze(0)\n",
        "      except:\n",
        "        x = torch.tensor([curr_time[\"px\"][j], curr_time[\"py\"][j], 0,0]).unsqueeze(0)\n",
        "      fish[\"x\"] = torch.cat((fish[\"x\"],x), dim=0)\n",
        "      fish_ids_to_idx[fish_idx[j]] = fish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkDRu5TjfdmK",
        "outputId": "3023322a-6faa-429d-d642-9b65d9bf574c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "104.00130220444609"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "avg = 0\n",
        "for k in fish_ids_to_idx.keys():\n",
        "  avg += len(fish_ids_to_idx[k][\"times\"])\n",
        "\n",
        "avg/len(fish_ids_to_idx.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Za9EempftXq"
      },
      "outputs": [],
      "source": [
        "fish_ids_to_idx[110450][\"times\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCClMYk1f9jH"
      },
      "outputs": [],
      "source": [
        "def create_y_for_fish(fish):\n",
        "  X = fish[\"x\"].T\n",
        "  t = fish[\"times\"]\n",
        "\n",
        "  x,y = create_y(X,t)\n",
        "  fish[\"x\"] = x\n",
        "  fish[\"y\"] = y\n",
        "  fish[\"times\"] = t[1:-1]\n",
        "  return fish\n",
        "\n",
        "def create_y(X,t):\n",
        "  N = X.shape[0]\n",
        "  T = X.shape[1]\n",
        "\n",
        "  n = N//4\n",
        "\n",
        "  y = torch.zeros(N,T)\n",
        "  for i in range(1,T-1):\n",
        "    y[:n,i] = X[2*n:3*n, i]\n",
        "    y[n:2*n,i] = X[3*n:, i]\n",
        "    y[2*n:,i] = (X[2*n:,i+1] - X[2*n:,i-1])/(t[i+1]-t[i-1])\n",
        "\n",
        "  return X[:,1:-1], y[:,1:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwTyczanwlXj"
      },
      "outputs": [],
      "source": [
        "for k in fish_ids_to_idx.keys():\n",
        "  fish_ids_to_idx[k] = create_y_for_fish(fish_ids_to_idx[k])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYiWniUs8Joe"
      },
      "outputs": [],
      "source": [
        "times_to_fish = {}\n",
        "keys = fish_ids_to_idx.keys()\n",
        "for t in range(1,5001):\n",
        "  fish_idx = []\n",
        "  for k in keys:\n",
        "    if t in fish_ids_to_idx[k][\"times\"]:\n",
        "      fish_idx.append(k)\n",
        "  times_to_fish[t] = fish_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGUnd2eHxNSK"
      },
      "outputs": [],
      "source": [
        "Xs = []\n",
        "Ys = []\n",
        "keys = fish_ids_to_idx.keys()\n",
        "for t in range(1,5001):\n",
        "  fish_idxs = times_to_fish[t]\n",
        "  x = torch.zeros(len(fish_idxs),4)\n",
        "  y = torch.zeros(len(fish_idxs),4)\n",
        "  for i,fish_id in enumerate(fish_idxs):\n",
        "    fish = fish_ids_to_idx[fish_id]\n",
        "    t_idx = fish[\"times\"].index(t)\n",
        "    x[i,:] = fish[\"x\"].T[t_idx,:]\n",
        "    y[i,:] = fish[\"y\"].T[t_idx,:]\n",
        "  Xs.append(x)\n",
        "  Ys.append(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5CI-ziRfl2z"
      },
      "outputs": [],
      "source": [
        "torch.save((Xs, Ys), \"drive/MyDrive/MeasureMaps/FishMilling.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNn3Uc2yG3JB"
      },
      "source": [
        "# Setting Up Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsT13ZQ4IOro"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import scipy.io as sio\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efkeaJDcIPSu"
      },
      "outputs": [],
      "source": [
        "# Throughout this we are going to assume that data is of the form B x N x D\n",
        "# Where B is the batch size, N is the sequence length for the transformer\n",
        "# this the number of data points. Finally D is the embedding dimension.\n",
        "class SimpleAttention(nn.Module):\n",
        "  # Initialize the parameter\n",
        "  def __init__(self, hidden_dim):\n",
        "    super(SimpleAttention, self).__init__()\n",
        "    self.linear = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.WQ = nn.Linear(hidden_dim, hidden_dim, bias = False)\n",
        "    self.WK = nn.Linear(hidden_dim, hidden_dim, bias = False)\n",
        "    self.WV = nn.Linear(hidden_dim, hidden_dim, bias = False)\n",
        "    self.skip = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.attention = nn.MultiheadAttention(hidden_dim, 1, batch_first=True)\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self, input):\n",
        "    Q = self.WQ(input)\n",
        "    K = self.WK(input)\n",
        "    V = self.WV(input)\n",
        "    output_attention,_ = self.attention(Q,K,V)\n",
        "    output_linear = self.linear(output_attention.relu()).relu()\n",
        "    return output_linear + self.skip(input)\n",
        "\n",
        "class SimpleTransformer(nn.Module):\n",
        "# Initialize the parameter\n",
        "  def __init__(self, input_dim, hidden_dim, out_dim, num_layers):\n",
        "    super(SimpleTransformer, self).__init__()\n",
        "    self.embed = nn.Linear(input_dim, hidden_dim)\n",
        "    self.predictor = nn.Linear(hidden_dim, out_dim)\n",
        "    self.AttentionLayers = []\n",
        "    for i in range(num_layers):\n",
        "      self.AttentionLayers.append(SimpleAttention(hidden_dim))\n",
        "\n",
        "    self.AttentionLayers = nn.ModuleList(self.AttentionLayers)\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self, z):\n",
        "    z = self.embed(z)\n",
        "    for i in range(self.num_layers):\n",
        "      z = self.AttentionLayers[i](z)\n",
        "    return self.predictor(z)\n",
        "\n",
        "\n",
        "class FNN(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, out_dim, num_layers, d):\n",
        "    super(FNN, self).__init__()\n",
        "    self.embed = nn.Linear(input_dim, hidden_dim)\n",
        "    self.predictor = nn.Linear(hidden_dim, out_dim)\n",
        "    self.Layers = []\n",
        "    for i in range(num_layers):\n",
        "      self.Layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "\n",
        "    self.Layers = nn.ModuleList(self.Layers)\n",
        "    self.num_layers = num_layers\n",
        "    self.d = d\n",
        "\n",
        "  # Input size B x N X 4\n",
        "  def forward(self,x):\n",
        "    x = torch.flatten(x, 1, 2) # B x N4\n",
        "    x = self.embed(x).relu()\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.Layers[i](x).relu()\n",
        "    x = self.predictor(x)\n",
        "    x = torch.unflatten(x, 1, (-1,self.d))\n",
        "    return x\n",
        "\n",
        "def kernel_basis(X, d1, d2):\n",
        "  N = X.shape[0]\n",
        "  d = X.shape[1]\n",
        "\n",
        "  Phi = torch.zeros(N, (d1+2*d2)*d, device = X.device)\n",
        "  for i in range(d1+2*d2):\n",
        "    if i < d1:\n",
        "      for j in range(d):\n",
        "        Phi[:,d*i+j] = X[:,j].pow(i+1)\n",
        "    elif i < d1+d2:\n",
        "      for j in range(d):\n",
        "        k = i-d1+1\n",
        "        Phi[:,d*i+j] = (X[:,j]*k).sin()\n",
        "    else:\n",
        "      for j in range(d):\n",
        "        k = i-d1-d2+1\n",
        "        Phi[:,d*i+j] = torch.cos(X[:,j]*k)\n",
        "\n",
        "  return Phi\n",
        "\n",
        "class Kernel(nn.Module):\n",
        "  def __init__(self, feature_dim, out_dim, d, embed=kernel_basis):\n",
        "    super(Kernel, self).__init__()\n",
        "    self.predictor = nn.Linear(feature_dim, out_dim, device = \"cuda\")\n",
        "    self.embed = embed\n",
        "    self.d = d\n",
        "\n",
        "  # Input size B x N X 4\n",
        "  def forward(self,x):\n",
        "    x = self.predictor(x)\n",
        "    x = torch.unflatten(x, 1, (-1,self.d))\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2g0EVF6JEqI"
      },
      "outputs": [],
      "source": [
        "def get_nn(in_channels, out_channels):\n",
        "  return torch.nn.Sequential(torch.nn.Linear(in_channels, out_channels), torch.nn.ReLU(),\n",
        "                             torch.nn.Linear(out_channels, out_channels))\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "  def __init__(self, node_input_dim, output_dim, num_layers, hidden_dim = 128, device = \"cuda\", arch = \"Graph\"):\n",
        "    super().__init__()\n",
        "\n",
        "    self.num_layers = num_layers\n",
        "    self.layers = []\n",
        "    if arch == \"Transformer\":\n",
        "      self.layers.append(torch_geometric.nn.TransformerConv(node_input_dim, hidden_dim).to(device))\n",
        "      for i in range(num_layers-1):\n",
        "        self.layers.append(torch_geometric.nn.TransformerConv(hidden_dim, hidden_dim).to(device))\n",
        "    elif arch == \"Graph\":\n",
        "      self.layers.append(torch_geometric.nn.GraphConv(node_input_dim, hidden_dim).to(device))\n",
        "      for i in range(num_layers-1):\n",
        "        self.layers.append(torch_geometric.nn.GraphConv(hidden_dim, hidden_dim).to(device))\n",
        "    elif arch == \"GIN\":\n",
        "      self.layers.append(torch_geometric.nn.GINConv(get_nn(node_input_dim, hidden_dim)).to(device))\n",
        "      for i in range(num_layers-1):\n",
        "        self.layers.append(torch_geometric.nn.GINConv(get_nn(hidden_dim, hidden_dim)).to(device))\n",
        "\n",
        "    self.layers = torch.nn.ModuleList(self.layers)\n",
        "    self.lin = torch.nn.Linear(hidden_dim, output_dim).to(device)\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.layers[i](x, edge_index).relu()\n",
        "\n",
        "    z = self.lin(x)\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRlIZKPztgWN"
      },
      "outputs": [],
      "source": [
        "class Cylindrical_FNN(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, out_dim, num_layers):\n",
        "    super(Cylindrical_FNN, self).__init__()\n",
        "    self.layers = []\n",
        "    self.layers.append(nn.Linear(input_dim, hidden_dim))\n",
        "    for i in range(num_layers-2):\n",
        "      self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "    self.layers.append(nn.Linear(hidden_dim, out_dim))\n",
        "\n",
        "    self.layers = nn.ModuleList(self.layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    for i in range(len(self.layers)):\n",
        "      x = self.layers[i](x).relu()\n",
        "    return x\n",
        "\n",
        "class Cylindrical(torch.nn.Module):\n",
        "  def __init__(self, node_input_dim, output_dim, num_layers_psi, num_layers_phi, hidden_dim = 128, device = \"cuda\"):\n",
        "    super().__init__()\n",
        "\n",
        "    self.psi = Cylindrical_FNN(node_input_dim, hidden_dim, hidden_dim, num_layers_psi).to(device)\n",
        "    self.phi = Cylindrical_FNN(hidden_dim+node_input_dim, hidden_dim, output_dim, num_layers_phi).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    z = self.psi(x)\n",
        "    z_mean = z.mean(dim=1).repeat(1, x.shape[1], 1)\n",
        "    z = torch.cat((z_mean,x), dim=-1)\n",
        "    z = self.phi(z)\n",
        "\n",
        "    return z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWouYiW9HEcJ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE7VqDvGb9Vo",
        "outputId": "1d72c3b1-9d9b-4dd2-878c-20fbd12e5d44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-db67106fc7b2>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  X, Y = torch.load(\"drive/MyDrive/MeasureMaps/FishMilling.pt\")\n"
          ]
        }
      ],
      "source": [
        "X, Y = torch.load(\"drive/MyDrive/MeasureMaps/FishMilling.pt\")\n",
        "\n",
        "# dataset_knn = data_to_GNN_data_fm(Xtrn, Ytrn, 3)\n",
        "# dataset_full = data_to_GNN_data_fm(Xtrn, Ytrn, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj7TR0W8a_fa",
        "outputId": "06fc1ba6-ab7c-40d7-da20-97b316c2125d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-497a7d560dad>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  train_idx = torch.load(\"drive/MyDrive/MeasureMaps/FM-data-split.pt\")\n"
          ]
        }
      ],
      "source": [
        "train_idx = torch.load(\"drive/MyDrive/MeasureMaps/FM-data-split.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgeB4KKy62vm"
      },
      "outputs": [],
      "source": [
        "Xtrn = [X[i] for i in train_idx]\n",
        "Ytrn = [Y[i] for i in train_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "okS60owkIIqY",
        "outputId": "7e3e1cc8-e446-493d-f670-833cbaae1722"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not tuple",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9e58d99e3753>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_loader_gnn_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_loader_gnn_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_knn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
          ]
        }
      ],
      "source": [
        "# train_data = torch.utils.data.TensorDataset(Xtrn[train_idx,:,:], Ytrn[train_idx,:,:])\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train_data, shuffle = True, batch_size=500)\n",
        "# train_loader_gnn_full = DataLoader([dataset_full[i] for i in train_idx.numpy()], shuffle = True, batch_size = 500)\n",
        "# train_loader_gnn_knn = DataLoader([dataset_knn[i] for i in train_idx.numpy()], shuffle = True, batch_size = 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "h35pUJd37HaH",
        "outputId": "1ace2138-0f96-4101-93f0-f03c33795b19"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 11/11 [01:19<00:00,  7.26s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.32s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.35s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.36s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.34s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.37s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.35s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.44s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.34s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.33s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.39s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.35s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.36s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.35s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.32s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.41s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.21s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.12s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.18s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.25s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.18s/it]\n",
            "100%|██████████| 11/11 [01:32<00:00,  8.39s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.23s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.24s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.22s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.41s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.33s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.38s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.43s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.36s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.41s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.34s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.42s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.36s/it]\n",
            "100%|██████████| 11/11 [01:22<00:00,  7.47s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.32s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.35s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.40s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.42s/it]\n",
            "100%|██████████| 11/11 [01:22<00:00,  7.46s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.38s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.43s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.14s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.15s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.12s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.17s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.16s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.20s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.17s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.15s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.16s/it]\n",
            "100%|██████████| 11/11 [01:19<00:00,  7.27s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.39s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.34s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.36s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.38s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.38s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.40s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.37s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.45s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.43s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.36s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.37s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.37s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.40s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.36s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.36s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.41s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.34s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.18s/it]\n",
            "100%|██████████| 11/11 [01:28<00:00,  8.09s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.18s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.26s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.24s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.25s/it]\n",
            "100%|██████████| 11/11 [01:31<00:00,  8.31s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.20s/it]\n",
            "100%|██████████| 11/11 [01:31<00:00,  8.35s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.41s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.41s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.40s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.36s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.36s/it]\n",
            "100%|██████████| 11/11 [01:22<00:00,  7.49s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.39s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.40s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.44s/it]\n",
            "100%|██████████| 11/11 [01:22<00:00,  7.49s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.37s/it]\n",
            "100%|██████████| 11/11 [01:23<00:00,  7.57s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.43s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.42s/it]\n",
            "100%|██████████| 11/11 [01:22<00:00,  7.48s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.42s/it]\n",
            "100%|██████████| 11/11 [01:22<00:00,  7.47s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.38s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.11s/it]\n",
            "100%|██████████| 11/11 [01:31<00:00,  8.33s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.18s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.23s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.20s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.27s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.24s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.19s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.22s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.44s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.35s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.36s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.42s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.32s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.38s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.36s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.38s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.32s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.34s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.39s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.36s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.39s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.37s/it]\n",
            "100%|██████████| 11/11 [01:20<00:00,  7.35s/it]\n",
            "100%|██████████| 11/11 [01:21<00:00,  7.40s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.15s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.23s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.12s/it]\n",
            "100%|██████████| 11/11 [01:29<00:00,  8.10s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.26s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.27s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.20s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.23s/it]\n",
            "100%|██████████| 11/11 [01:30<00:00,  8.22s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "depths = [3,4,5]\n",
        "widths = [128,256,512]\n",
        "lrs = [2e-4, 1e-3, 1e-4]\n",
        "T = 5\n",
        "N = len(Xtrn)\n",
        "\n",
        "epochs = 11\n",
        "\n",
        "for t in range(T):\n",
        "  for d in depths: # depth\n",
        "    for h in widths: # width\n",
        "      for lr in lrs:\n",
        "        if os.path.exists(\"drive/MyDrive/MeasureMaps/Cylindrical/fm-trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-\"+str(10)+\".pt\"):\n",
        "          print(\"Done with\",t,d,h,lr)\n",
        "          continue\n",
        "        model_cylin = Cylindrical(4,4,d//2, d - d//2, h).to('cuda')\n",
        "\n",
        "        optimizer_cylin = torch.optim.Adam(model_cylin.parameters(), lr = lr)\n",
        "        scheduler_cylin = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_cylin, epochs)\n",
        "\n",
        "        for i in tqdm(range(epochs)):\n",
        "          for j in range(N):\n",
        "            optimizer_cylin.zero_grad()\n",
        "            X = Xtrn[j].to('cuda').unsqueeze(0)\n",
        "            Y = Ytrn[j].to('cuda').unsqueeze(0)\n",
        "            Y_pred = model_cylin(X)\n",
        "            loss = torch.nn.functional.mse_loss(Y_pred, Y)\n",
        "            loss.backward()\n",
        "            optimizer_cylin.step()\n",
        "          torch.save(model_cylin,\"drive/MyDrive/MeasureMaps/Cylindrical/fm-trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-\"+str(i)+\".pt\")\n",
        "          scheduler_cylin.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aWeai7rWdbYN"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "depths = [3,4,5]\n",
        "widths = [128,256,512]\n",
        "lrs = [2e-4, 1e-3, 1e-4]\n",
        "T = 5\n",
        "N = len(train_X)\n",
        "\n",
        "epochs = 11\n",
        "\n",
        "for t in range(T):\n",
        "  for d in depths: # depth\n",
        "    for h in widths: # width\n",
        "      for lr in lrs:\n",
        "        if os.path.exists(\"drive/MyDrive/MeasureMaps/Transformer/fm-trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-\"+str(10)+\".pt\"):\n",
        "          print(\"Done with\",t,d,h,lr)\n",
        "          continue\n",
        "        model_transformer = SimpleTransformer(4,h,4,d).to('cuda')\n",
        "\n",
        "        optimizer_transformer = torch.optim.Adam(model_transformer.parameters(), lr = lr)\n",
        "        scheduler_transformer = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_transformer, epochs)\n",
        "\n",
        "        for i in tqdm(range(epochs)):\n",
        "          for j in range(N):\n",
        "            optimizer_transformer.zero_grad()\n",
        "            X = train_X[j].to('cuda')\n",
        "            Y = train_Y[j].to('cuda')\n",
        "            Y_pred = model_transformer(X)\n",
        "            loss = torch.nn.functional.mse_loss(Y_pred, Y)\n",
        "            loss.backward()\n",
        "            optimizer_transformer.step()\n",
        "          # torch.save(model_transformer,\"drive/MyDrive/MeasureMaps/Transformer/fm-trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-\"+str(i)+\".pt\")\n",
        "          scheduler_transformer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lZzreSBFl25g"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "degree = [2,3,4]\n",
        "frequencies = [4,5,6]\n",
        "lrs = [1e-4, 2e-4, 1e-3]\n",
        "T = 5\n",
        "\n",
        "epochs = 1001\n",
        "\n",
        "for t in range(T):\n",
        "  for d1 in degree:\n",
        "    for d2 in frequencies:\n",
        "      for lr in lrs:\n",
        "        if os.path.exists(\"drive/MyDrive/MeasureMaps/Kernel/trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-\"+str(1000)+\".pt\"):\n",
        "          continue\n",
        "        Xtrn_data_kernel = kernel_basis(torch.flatten(Xtrn_data,1,2),d1,d2)\n",
        "        train_data_kernel = torch.utils.data.TensorDataset(Xtrn_data_kernel[train_idx,:], Ytrn_data[train_idx,:,:])\n",
        "        train_loader_kernel = torch.utils.data.DataLoader(train_data_kernel, shuffle = True, batch_size=500)\n",
        "\n",
        "        model_kernel = Kernel((d1+2*d2)*4*20,80,4).to('cuda')\n",
        "\n",
        "        optimizer_kernel = torch.optim.Adam(model_kernel.parameters(), lr = lr)\n",
        "        scheduler_kernel = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_kernel, epochs)\n",
        "\n",
        "        for i in tqdm(range(epochs)):\n",
        "          for X,Y in train_loader_kernel:\n",
        "            optimizer_kernel.zero_grad()\n",
        "            Y_pred = model_kernel(X)\n",
        "            loss = torch.nn.functional.mse_loss(Y_pred, Y)\n",
        "            loss.backward()\n",
        "            optimizer_kernel.step()\n",
        "          if i % 100 == 0:\n",
        "            torch.save(model_kernel,\"drive/MyDrive/MeasureMaps/Kernel/trial-\"+str(t)+\"-degree-\"+str(d1)+\"-frequency-\"+str(d2)+\"-lr-\"+str(lr)+\"-epoch-\"+str(i)+\".pt\")\n",
        "          scheduler_kernel.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c20j3ohMe8gV"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "depths = [3,4,5]\n",
        "widths = [128,256,512]\n",
        "lrs = [1e-4, 2e-4, 1e-3]\n",
        "T = 5\n",
        "N = 20\n",
        "\n",
        "epochs = 1001\n",
        "\n",
        "for t in range(1):\n",
        "  for d in depths:\n",
        "    for h in widths:\n",
        "      for lr in lrs:\n",
        "        if os.path.exists(\"drive/MyDrive/MeasureMaps/FNN/trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-\"+str(1000)+\".pt\"):\n",
        "          continue\n",
        "        model_fnn = FNN(4*N,h,4*N,d,4).to('cuda')\n",
        "\n",
        "\n",
        "        optimizer_fnn = torch.optim.Adam(model_fnn.parameters(), lr = lr)\n",
        "        scheduler_fnn = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_fnn, epochs)\n",
        "\n",
        "        for i in tqdm(range(epochs)):\n",
        "          for X,Y in train_loader:\n",
        "            optimizer_fnn.zero_grad()\n",
        "            Y_pred = model_fnn(X)\n",
        "            loss = torch.nn.functional.mse_loss(Y_pred, Y)\n",
        "            loss.backward()\n",
        "            optimizer_fnn.step()\n",
        "          if i % 100 == 0:\n",
        "            torch.save(model_fnn,\"drive/MyDrive/MeasureMaps/FNN/trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-\"+str(i)+\".pt\")\n",
        "          scheduler_fnn.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKhoLgHPfZyz"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "depths = [3,4,5]\n",
        "widths = [128,256,512]\n",
        "lrs = [1e-4, 2e-4, 1e-3]\n",
        "T = 5\n",
        "\n",
        "epochs = 501\n",
        "\n",
        "for t in range(T):\n",
        "  for d in depths:\n",
        "    for h in widths:\n",
        "      for lr in lrs:\n",
        "        # if os.path.exists(\"drive/MyDrive/MeasureMaps/GNN/GraphConv Full/fm-trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-\"+str(10)+\".pt\"):\n",
        "        #   print(\"done with\", t, d, h, lr)\n",
        "        #   continue\n",
        "        model_gnn = GNN(4,4,d,h).to('cuda')\n",
        "\n",
        "\n",
        "        optimizer_gnn = torch.optim.Adam(model_gnn.parameters(), lr = lr)\n",
        "        scheduler_gnn = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_gnn, epochs)\n",
        "\n",
        "        for i in tqdm(range(epochs)):\n",
        "          for data in train_loader_gnn_full:\n",
        "            optimizer_gnn.zero_grad()\n",
        "            data = data.to('cuda')\n",
        "            Y_pred = model_gnn(data.x, data.edge_index, data.batch)\n",
        "            loss = torch.nn.functional.mse_loss(Y_pred, data.y)\n",
        "            loss.backward()\n",
        "            optimizer_gnn.step()\n",
        "          print(loss)\n",
        "          torch.save(model_gnn,\"drive/MyDrive/MeasureMaps/GNN/GraphConv Full/fm-trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-\"+str(i)+\".pt\")\n",
        "          scheduler_gnn.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiYbgHl7gfA9"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "depths = [3,4,5]\n",
        "widths = [128,256,512]\n",
        "lrs = [1e-4, 2e-4, 1e-3]\n",
        "T = 5\n",
        "\n",
        "epochs = 11\n",
        "\n",
        "for t in range(T):\n",
        "  for d in depths:\n",
        "    for h in widths:\n",
        "      for lr in lrs:\n",
        "        # if os.path.exists(\"drive/MyDrive/MeasureMaps/GNN/GraphConv KNN/fm-trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-\"+str(10)+\".pt\"):\n",
        "        #   print(\"Done with\",t,d,h,lr)\n",
        "        #   continue\n",
        "        model_gnn = GNN(4,4,d,h).to('cuda')\n",
        "\n",
        "\n",
        "        optimizer_gnn = torch.optim.Adam(model_gnn.parameters(), lr = lr)\n",
        "        scheduler_gnn = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_gnn, epochs)\n",
        "\n",
        "        for i in tqdm(range(epochs)):\n",
        "          for data in train_loader_gnn_knn:\n",
        "            optimizer_gnn.zero_grad()\n",
        "            data = data.to('cuda')\n",
        "            Y_pred = model_gnn(data.x, data.edge_index, data.batch)\n",
        "            loss = torch.nn.functional.mse_loss(Y_pred, data.y)\n",
        "            loss.backward()\n",
        "            optimizer_gnn.step()\n",
        "          print(loss)\n",
        "          # torch.save(model_gnn,\"drive/MyDrive/MeasureMaps/GNN/GraphConv KNN/fm-trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-\"+str(i)+\".pt\")\n",
        "          scheduler_gnn.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lcuczXGAhN9C"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "depths = [3,4,5]\n",
        "widths = [128,256,512]\n",
        "lrs = [1e-4, 2e-4, 1e-3]\n",
        "T = 5\n",
        "\n",
        "epochs = 11\n",
        "\n",
        "for t in range(T):\n",
        "  for d in depths:\n",
        "    for h in widths:\n",
        "      for lr in lrs:\n",
        "        # if os.path.exists(\"drive/MyDrive/MeasureMaps/GNN/TransformerConv Full/fm-trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-\"+str(10)+\".pt\"):\n",
        "        #   print(\"Done with\",t,d,h,lr)\n",
        "        #   continue\n",
        "        model_gnn = GNN(4,4,d,h,arch=\"Transformer\").to('cuda')\n",
        "\n",
        "\n",
        "        optimizer_gnn = torch.optim.Adam(model_gnn.parameters(), lr = lr)\n",
        "        scheduler_gnn = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_gnn, epochs)\n",
        "\n",
        "        for i in tqdm(range(epochs)):\n",
        "          for data in train_loader_gnn_full:\n",
        "            optimizer_gnn.zero_grad()\n",
        "            data = data.to('cuda')\n",
        "            Y_pred = model_gnn(data.x, data.edge_index, data.batch)\n",
        "            loss = torch.nn.functional.mse_loss(Y_pred, data.y)\n",
        "            loss.backward()\n",
        "            optimizer_gnn.step()\n",
        "          print(loss)\n",
        "          # torch.save(model_gnn,\"drive/MyDrive/MeasureMaps/GNN/TransformerConv Full/fm-trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-\"+str(i)+\".pt\")\n",
        "          scheduler_gnn.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfNKKVtzhNvg"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "depths = [3,4,5]\n",
        "widths = [128,256,512]\n",
        "lrs = [1e-4, 2e-4, 1e-3]\n",
        "T = 5\n",
        "\n",
        "epochs = 11\n",
        "\n",
        "for t in range(T):\n",
        "  for d in depths:\n",
        "    for h in widths:\n",
        "      for lr in lrs:\n",
        "        if os.path.exists(\"drive/MyDrive/MeasureMaps/GNN/TransformerConv KNN/fm-trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-\"+str(10)+\".pt\"):\n",
        "          print(\"Done with\",t,d,h,lr)\n",
        "          continue\n",
        "        model_gnn = GNN(4,4,d,h,arch=\"Transformer\").to('cuda')\n",
        "\n",
        "        optimizer_gnn = torch.optim.Adam(model_gnn.parameters(), lr = lr)\n",
        "        scheduler_gnn = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_gnn, epochs)\n",
        "\n",
        "        for i in tqdm(range(epochs)):\n",
        "          for data in train_loader_gnn_knn:\n",
        "            optimizer_gnn.zero_grad()\n",
        "            data = data.to('cuda')\n",
        "            Y_pred = model_gnn(data.x, data.edge_index, data.batch)\n",
        "            loss = torch.nn.functional.mse_loss(Y_pred, data.y)\n",
        "            loss.backward()\n",
        "            optimizer_gnn.step()\n",
        "          torch.save(model_gnn,\"drive/MyDrive/MeasureMaps/GNN/TransformerConv KNN/fm-trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-\"+str(i)+\".pt\")\n",
        "          scheduler_gnn.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU4pWjQGymWh"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZJNc7DBHnXP"
      },
      "outputs": [],
      "source": [
        "Xtrn, Ytrn = torch.load(\"drive/MyDrive/MeasureMaps/FishMilling.pt\")\n",
        "train_idx = torch.load(\"drive/MyDrive/MeasureMaps/FM-data-split.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-uW2vtuHnLb"
      },
      "outputs": [],
      "source": [
        "val_idx = torch.load(\"drive/MyDrive/MeasureMaps/FM-val-idx.pt\")\n",
        "test_idx = torch.load(\"drive/MyDrive/MeasureMaps/FM-test-idx.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKgbyq4fHnGK"
      },
      "outputs": [],
      "source": [
        "dataset_knn = data_to_GNN_data_fm(Xtrn, Ytrn, 3)\n",
        "dataset_full = data_to_GNN_data_fm(Xtrn, Ytrn, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1tTEuQAHnAT"
      },
      "outputs": [],
      "source": [
        "val_X = [Xtrn[i] for i in val_idx]\n",
        "val_Y = [Ytrn[i] for i in val_idx]\n",
        "\n",
        "val_loader_gnn_full = DataLoader([dataset_full[i] for i in val_idx.numpy()], shuffle = True, batch_size = 1)\n",
        "val_loader_gnn_knn = DataLoader([dataset_knn[i] for i in val_idx.numpy()], shuffle = True, batch_size = 1)\n",
        "\n",
        "test_X = [Xtrn[i] for i in test_idx]\n",
        "test_Y = [Ytrn[i] for i in test_idx]\n",
        "\n",
        "test_loader_gnn_full = DataLoader([dataset_full[i] for i in test_idx.numpy()], shuffle = True, batch_size = 1)\n",
        "test_loader_gnn_knn = DataLoader([dataset_knn[i] for i in test_idx.numpy()], shuffle = True, batch_size = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6Q_cEZ8Hm5S"
      },
      "outputs": [],
      "source": [
        "def test_transformer_fm(model, loader_X, loader_Y):\n",
        "  N = len(loader_Y)\n",
        "  loss = torch.zeros(N)\n",
        "  model.eval()\n",
        "  for i in range(N):\n",
        "    X = loader_X[i].to('cuda')\n",
        "    Y = loader_Y[i].to('cuda')\n",
        "    Y_pred = model(X)\n",
        "    loss[i] = torch.nn.functional.mse_loss(Y_pred, Y).cpu().detach()\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYQT51XrHmzT"
      },
      "outputs": [],
      "source": [
        "depths = [3,4,5]\n",
        "widths = [128,256,512]\n",
        "lrs = [2e-4, 1e-3, 1e-4]\n",
        "T = 5\n",
        "\n",
        "best_loss = 100000\n",
        "best_d = -1\n",
        "best_w = -1\n",
        "best_lr = -1\n",
        "\n",
        "for d in depths: # depth\n",
        "  for h in widths: # width\n",
        "    for lr in lrs:\n",
        "      avg_loss = 0\n",
        "      print(\"Testing: \",d,h,lr)\n",
        "      for t in range(T):\n",
        "        model = torch.load(\"drive/MyDrive/MeasureMaps/Transformer/fm-trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-10.pt\")\n",
        "        loss = test_transformer_fm(model, val_X, val_Y)\n",
        "        avg_loss += loss.mean()/T\n",
        "      if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        best_d = d\n",
        "        best_w = h\n",
        "        best_lr = lr\n",
        "print(best_loss, best_d, best_w, best_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdASyiDp925D",
        "outputId": "a7147821-23bc-4705-96fa-94379ef46f7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0222) tensor(1.8757e-05)\n"
          ]
        }
      ],
      "source": [
        "loss_avg = torch.zeros(5)\n",
        "loss_std = torch.zeros(5)\n",
        "for t in range(T):\n",
        "  model = torch.load(\"drive/MyDrive/MeasureMaps/Transformer/fm-trial-\"+str(t)+\"-depth-\"+str(best_d)+\"-width-\"+str(best_w)+\"-lr-\"+str(best_lr)+\"-epoch-10.pt\")\n",
        "  loss = test_transformer_fm(model, test_X, test_Y)\n",
        "  loss_avg[t] = loss.mean()\n",
        "  loss_std[t] = loss.std()\n",
        "print(loss_avg.mean(), loss_avg.std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o27GEiwgBBB6"
      },
      "outputs": [],
      "source": [
        "def test_GNN_fm(model, loader):\n",
        "  N = len(loader)\n",
        "  loss = torch.zeros(N)\n",
        "  model.eval()\n",
        "  i = 0\n",
        "  for data in loader:\n",
        "    data = data.to('cuda')\n",
        "    Y_pred = model(data.x, data.edge_index, data.batch)\n",
        "    loss[i] = torch.nn.functional.mse_loss(Y_pred, data.y).cpu().detach()\n",
        "    i += 1\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9ghP4aVBetS",
        "outputId": "4a2ba166-78b5-40ec-ffe6-5d794cdf527b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing:  3 128 0.0002\n",
            "tensor(24886930.)\n",
            "Testing:  3 128 0.001\n",
            "tensor(8389030.)\n",
            "Testing:  3 128 0.0001\n",
            "tensor(1.5088e+08)\n",
            "Testing:  3 256 0.0002\n",
            "tensor(7238146.5000)\n",
            "Testing:  3 256 0.001\n",
            "tensor(8501644.)\n",
            "Testing:  3 256 0.0001\n",
            "tensor(7180415.5000)\n",
            "Testing:  3 512 0.0002\n",
            "tensor(6561584.)\n",
            "Testing:  3 512 0.001\n",
            "tensor(5210658.)\n",
            "Testing:  3 512 0.0001\n",
            "tensor(4909415.)\n",
            "Testing:  4 128 0.0002\n",
            "tensor(1.1334e+09)\n",
            "Testing:  4 128 0.001\n",
            "tensor(4.5062e+08)\n",
            "Testing:  4 128 0.0001\n",
            "tensor(2.8523e+09)\n",
            "Testing:  4 256 0.0002\n",
            "tensor(4.7832e+08)\n",
            "Testing:  4 256 0.001\n",
            "tensor(2.3417e+08)\n",
            "Testing:  4 256 0.0001\n",
            "tensor(1.6139e+09)\n",
            "Testing:  4 512 0.0002\n",
            "tensor(3.8287e+08)\n",
            "Testing:  4 512 0.001\n",
            "tensor(1.9696e+08)\n",
            "Testing:  4 512 0.0001\n",
            "tensor(3.9414e+08)\n",
            "Testing:  5 128 0.0002\n",
            "tensor(5.4111e+10)\n",
            "Testing:  5 128 0.001\n",
            "tensor(2.2792e+10)\n",
            "Testing:  5 128 0.0001\n",
            "tensor(3.1073e+11)\n",
            "Testing:  5 256 0.0002\n",
            "tensor(2.9897e+10)\n",
            "Testing:  5 256 0.001\n",
            "tensor(1.2194e+10)\n",
            "Testing:  5 256 0.0001\n",
            "tensor(4.4744e+10)\n",
            "Testing:  5 512 0.0002\n",
            "tensor(2.8784e+10)\n",
            "Testing:  5 512 0.001\n",
            "tensor(1.2767e+10)\n",
            "Testing:  5 512 0.0001\n",
            "tensor(3.0203e+10)\n",
            "100000 -1 -1 -1\n"
          ]
        }
      ],
      "source": [
        "depths = [3,4,5]\n",
        "widths = [128,256,512]\n",
        "lrs = [2e-4, 1e-3, 1e-4]\n",
        "T = 5\n",
        "\n",
        "best_loss = 100000\n",
        "best_d = -1\n",
        "best_w = -1\n",
        "best_lr = -1\n",
        "\n",
        "for d in depths: # depth\n",
        "  for h in widths: # width\n",
        "    for lr in lrs:\n",
        "      avg_loss = 0\n",
        "      print(\"Testing: \",d,h,lr)\n",
        "      for t in range(T):\n",
        "        model = torch.load(\"drive/MyDrive/MeasureMaps/GNN/GraphConv Full/fm-trial-\"+str(t)+\"-depth-\"+str(d)+\"-width-\"+str(h)+\"-lr-\"+str(lr)+\"-epoch-10.pt\")\n",
        "        loss = test_GNN_fm(model, val_loader_gnn_full)\n",
        "        avg_loss += loss.mean()/T\n",
        "      print(avg_loss)\n",
        "      if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        best_d = d\n",
        "        best_w = h\n",
        "        best_lr = lr\n",
        "print(best_loss, best_d, best_w, best_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDvQfqO2BooA",
        "outputId": "14f7c538-a83a-4b69-84c7-f55c52f72934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1210) tensor(0.0207)\n"
          ]
        }
      ],
      "source": [
        "loss_avg = torch.zeros(5)\n",
        "loss_std = torch.zeros(5)\n",
        "for t in range(T):\n",
        "  model = torch.load(\"drive/MyDrive/MeasureMaps/GNN/GraphConv Full/fm-trial-\"+str(t)+\"-depth-\"+str(best_d)+\"-width-\"+str(best_w)+\"-lr-\"+str(best_lr)+\"-epoch-10.pt\")\n",
        "  loss = test_GNN_fm(model, test_loader_gnn_full)\n",
        "  loss_avg[t] = loss.mean()\n",
        "  loss_std[t] = loss.std()\n",
        "print(loss_avg.mean(), loss_avg.std())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}